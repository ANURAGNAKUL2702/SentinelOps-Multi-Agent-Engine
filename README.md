# ğŸ® Autonomous War-Room Simulator

AI-powered incident response simulation with end-to-end root cause analysis, automated reporting, and historical analytics.

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚  Simulation  â”‚â”€â”€â–¶â”‚ Observabilityâ”‚â”€â”€â–¶â”‚  7-Agent Pipeline â”‚â”€â”€â–¶â”‚ Reporting â”‚â”€â”€â–¶â”‚  DB  â”‚
â”‚  Engine      â”‚   â”‚  (Metrics,   â”‚   â”‚  (Orchestrator)   â”‚   â”‚ (HTML,    â”‚   â”‚      â”‚
â”‚  (Phases 1-3)â”‚   â”‚   Logs, Deps)â”‚   â”‚  (Phases 5-11)    â”‚   â”‚  JSON, â€¦) â”‚   â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜
       Phase 1-3         Phase 4             Phase 5-11          Phase 12       Phase 12
```

**Phase 13 (this layer)** wires all 12 phases into a single CLI application.

## Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run a simulation
python main.py run --scenario database_timeout --format html

# List available scenarios
python main.py list-scenarios

# See all commands
python main.py --help
```

## CLI Commands

| Command            | Description                                      |
|--------------------|--------------------------------------------------|
| `run`              | Run an incident simulation and generate reports  |
| `list-scenarios`   | List all available incident scenarios            |
| `analyze`          | Analyze historical incidents from the database   |
| `dashboard`        | Generate an executive dashboard HTML             |
| `serve`            | Start the REST API server                        |
| `validate`         | Validate the configuration file                  |
| `interactive`      | Interactive mode with guided prompts             |
| `export-metrics`   | Export pipeline metrics (Prometheus format)       |
| `version`          | Show version and dependency information          |

### Examples

```bash
# Run with multiple report formats
python main.py run -s memory_leak -f html -f json

# Analyze last 7 days, filter by severity
python main.py analyze --days 7 --severity P1

# Generate dashboard
python main.py dashboard --days 30 -o dashboard.html

# Start API server
python main.py serve --port 8000

# Validate configuration
python main.py validate --config config.yaml

# Interactive mode
python main.py interactive
```

## Available Scenarios

| Scenario           | Description                                  | Severity    |
|--------------------|----------------------------------------------|-------------|
| `memory_leak`      | Gradual heap exhaustion on payment-service   | P2 MEDIUM   |
| `cpu_spike`        | Sudden CPU saturation on fraud scoring       | P1 HIGH     |
| `database_timeout` | Primary database becomes unresponsive        | P0 CRITICAL |
| `network_latency`  | Upstream network degradation at API gateway  | P1 HIGH     |

## Configuration

All settings live in `config.yaml`. Key sections:

```yaml
system:
  log_level: INFO          # DEBUG | INFO | WARNING | ERROR

simulation:
  default_scenario: database_timeout
  duration_minutes: 30

orchestrator:
  pipeline_timeout_seconds: 60
  enable_parallel_execution: true

reporting:
  default_formats: [html, json]
  output_directory: reports
  database:
    url: sqlite:///incidents.db
```

### Environment Variable Overrides

| Variable               | Config Path                    |
|------------------------|--------------------------------|
| `WARROOM_LOG_LEVEL`    | `system.log_level`             |
| `WARROOM_DATABASE_URL` | `reporting.database.url`       |
| `WARROOM_API_ENABLED`  | `api.enabled`                  |
| `WARROOM_API_PORT`     | `api.port`                     |
| `WARROOM_OUTPUT_DIR`   | `reporting.output_directory`   |

## Project Structure

```
app/
â”œâ”€â”€ main.py                    # CLI entry point (Click)
â”œâ”€â”€ config.yaml                # Central configuration
â”œâ”€â”€ conftest.py                # Pytest path setup
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ integration/               # Phase 13 â€” integration layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_manager.py      # Pydantic v2 config models + loader
â”‚   â”œâ”€â”€ logger.py              # Structlog setup with correlation IDs
â”‚   â”œâ”€â”€ cli.py                 # Rich output helpers & validation
â”‚   â””â”€â”€ pipeline.py            # WarRoomPipeline end-to-end orchestrator
â”‚
â”œâ”€â”€ simulation/                # Phases 1-3 â€” incident simulation
â”œâ”€â”€ observability/             # Phase 4 â€” metrics, logs, dependencies
â”œâ”€â”€ agents/                    # Phases 5-10 â€” AI analysis agents
â”œâ”€â”€ orchestrator/              # Phase 11 â€” pipeline orchestration
â”œâ”€â”€ reporting/                 # Phase 12 â€” reports, dashboard, API, DB
â”œâ”€â”€ schemas/                   # Shared Pydantic schemas
â”œâ”€â”€ analysis/                  # Analysis utilities
â”œâ”€â”€ validation/                # Validation framework
â”‚
â””â”€â”€ tests/
    â””â”€â”€ integration/           # Phase 13 integration tests
        â”œâ”€â”€ test_end_to_end.py # Full pipeline tests
        â”œâ”€â”€ test_scenarios.py  # Per-scenario tests
        â”œâ”€â”€ test_cli.py        # CLI command tests
        â””â”€â”€ test_config.py     # Configuration tests
```

## Pipeline Flow

1. **Simulation** â€” Generates realistic incident data (metrics, logs, services, blast radius)
2. **Observability** â€” Builds queryable metrics/log stores from simulation output
3. **Analysis** â€” 7 AI agents run in parallel DAG: log analysis â†’ metrics analysis â†’ dependency mapping â†’ hypothesis generation â†’ root cause analysis â†’ validation â†’ incident response
4. **Reporting** â€” Generates HTML/JSON/Markdown reports with visualizations
5. **Database** â€” Persists incidents for historical analytics (MTTR, MTTD, SLO compliance)

## Testing

```bash
# Run all tests (1020 tests)
python -m pytest -v

# Run integration tests only (102 tests)
python -m pytest tests/integration/ -v

# Run with coverage
python -m pytest --cov=integration tests/integration/
```

## Exit Codes

| Code | Meaning         |
|------|-----------------|
| 0    | Success         |
| 1    | User error      |
| 2    | System error    |
| 3    | Partial success |

## License

Internal use only.
